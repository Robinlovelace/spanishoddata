% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/convert_data.R
\name{spod_convert_od_v1_to_duckdb}
\alias{spod_convert_od_v1_to_duckdb}
\title{Convert all downloaded v1 origin-destination data to duckdb}
\usage{
spod_convert_od_v1_to_duckdb(
  zones = c("districts", "dist", "distr", "distritos", "municipalities", "muni",
    "municip", "municipios"),
  data_dir = spod_get_data_dir(),
  save_dir = NULL,
  quiet = FALSE,
  duck_max_mem = 3,
  duck_max_threads = parallelly::availableCores(),
  overwrite = FALSE
)
}
\arguments{
\item{zones}{The zones for which to download the data. Can be \code{"districts"} (or \code{"dist"}, \code{"distr"}, or the original Spanish \code{"distritos"}) or \code{"municipalities"} (or \code{"muni"}, \code{"municip"}, or the original Spanish \code{"municipios"}).}

\item{data_dir}{The directory where the data is stored.}

\item{save_dir}{The path to the directory where the duckdb files will be saved. If \code{NULL}, uses the default location in \code{data_dir} (set by the \code{SPANISH_OD_DATA_DIR} environment variable). Therefore, the default relative path is \verb{<data_dir>/clean_data/v1/tabular/duckdb/od_<zones>.duckdb}.}

\item{quiet}{Whether to suppress messages. Defaults to \code{FALSE}.}

\item{duck_max_mem}{The maximum memory to use in GB. A conservative default is 3 GB, which should be enough for resaving the data to DuckDB form a folder of CSV.gz files while being small enough to fit in memory of most even old computers. For data analysis using the already converted data (in DuckDB or Parquet format) or with the raw CSV.gz data, it is recommended to increase it according to available resources.}

\item{duck_max_threads}{The maximum number of threads to use. Defaults to the number of available cores minus 1.}

\item{overwrite}{Logical. If \code{TRUE}, overwrites existing duckdb files. Defaults to \code{FALSE}.}
}
\value{
Path to saved DuckDB file.
}
\description{
Convert all downloaded v1 origin-destination data to duckdb
}
