[{"path":"https://robinlovelace.github.io/spanishoddata/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 spanishoddata authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"convert-data","dir":"Articles","previous_headings":"","what":"Introduction","title":"Download and convert OD datasets","text":"spod_get() returns objects appropriate small datasets representing days national OD datasets. recommend converting data analysis-ready formats (DuckDB Parquet), allowing work large datasets consumer laptop (8-16 GB memory). Converting data either DuckDB Parquet can lead ~10x speed-compared using data frames returned spod_get(), reads CSV files every time call . DuckDB Parquet systems efficiently processing larger--memory datasets. introduction , recommend materials Danielle Navarro, Jonathan Keane, Stephanie Hazlitt: website, slides, video tutorial. Learning use DuckDB Parquet easy anyone ever worked dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. However, since learning curve master new tools, provide helper functions novices get started easily open datasets DuckDB Parquet. Please read . first show convert data, use . choice converting DuckDB Parquet made based needs: plan download large amounts data, recommend DuckDB, one big file easier update completely example first use dates 2020, later decided add dates 2021. case better delete database create scratch. want certain dates, analysis add dates later, Parquet may better, day saved separate file, just like original CSV files. Therefore updating folder Parquet files easy just creating new file missing date. testing (see Figure 1), using DuckDB database significant speed advantage running analysis raw CSV.gz files (DuckDB 8 times faster), even Parquet files (DuckDB 5 times faster). approaches working formats exactly , just use dplyr package functions selecting, grouping, filtering summarizing data. Figure 1: Data processing speed comparison: DuckDB engine running CSV.gz files vs DuckDB database vs folder Parquet files reference, simple query used speed comparison Figure 1: Figure 1 also shows DuckDB format also give best performance even low-end systems limited memory number processor cores, conditional fast SSD storage.","code":"data |>   group_by(id_origin, id_destination, time_slot) |>    summarise(mean_hourly_trips = mean(n_trips, na.rm = TRUE),     .groups = \"drop\")"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"spod-get","dir":"Articles","previous_headings":"","what":"Getting a single day with spod_get()","title":"Download and convert OD datasets","text":"can get single day’s worth data -memory object spod_get(): output look like : Note lazily-evaluated -memory object (note :memory: database path). means data loaded memory call collect() . useful quick exploration data, recommended large datasets. can convert already downloaded data DuckDB database. example, select dates, download data manually (note: use dates_2 refer fact using v2 data): , can convert downloaded data (including files might downloaded previosly running spod_get() spod_download_data() dates date intervals) DuckDB like (dates = \"cached_v2\" means use downloaded files): dates = \"cached_v2\" (can also dates = \"cached_v1\" v1 data) argument instructs function work already-downloaded files. default resulting DuckDB database v2 origin-destination data districts saved SPANISH_OD_DATA_DIR directory v2/tabular/duckdb/ filename od_distritos.duckdb (can change file path save_path argument). function returns full path database file, save db_2 variable. can also desired save location save_path argument spod_convert(). can also convert dates range dates list DuckDB: case, missing data now yet downloaded automatically downloaded, 2020-02-17 redownloaded, already requsted creating db_1. requested dates converted DuckDB, overwriting file db_1. , save path output DuckDB database file db_2 variable. can read introductory information connect DuckDB files , however simplify things created helper function. connect data stored path db_1 db_2 can following: Just like , spod_get() funciton used download raw CSV.gz files analyse without conversion, resulting object my_od_data_2 also tbl_duckdb_connection. , can treat regular data.frame tibble use dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. finishing working my_od_data_2 advise “disconnect” data using: useful free-memory neccessary like run spod_convert() save data location. Otherwise, also helpful avoid unnecessary possible warnings terminal garbage collected connections. process exactly DuckDB . difference data converted parquet format stored SPANISH_OD_DATA_DIR v1/clean_data/tabular/parquet/ directory v1 data (change save_path argument), subfolders hive-style format like year=2020/month=2/day=14 inside folders single parquet file placed containing data day. advantage format can “update” quickly. example, first downloaded data March April 2020, converted period parquet format, downloaded data May June 2020, run convertion function , convert data May June 2020 add existing parquet files. save time wait March April 2020 converted . Let us convert dates parquet format: now request additional dates overlap already converted data like specifiy argument overwrite = 'update' update existing parquet files new data: , 16 17 Feboruary converted . new data, converted (18 19 February) converted, added existing folder structure ofparquet files stored default save_path location, <data_dir>/clean_data/v1/tabular/parquet/od_distritos. Alternatively, can set save location setting save_path argument. Working parquet files exactly DuckDB Arrow files. Just like , can use helper function spod_connect() connect parquet files: Mind though, first converted data period 14 17 February 2020, converted data period 16 19 February 2020 save default location, od_parquet contains path data, therefore my_od_data_3 connect data. can check like : prepare origin-destination data v1 (2020-2021) analysis whole period data availability, please follow steps :","code":"dates <- c(\"2024-03-01\") d_1 <- spod_get(type = \"od\", zones = \"distr\", dates = dates) class(d_1) # Source:   table<od_csv_clean_filtered> [?? x 19] # Database: DuckDB v1.0.0 [... 6.5.0-45-generic:R 4.4.1/:memory:]    date       time_slot id_origin id_destination distance activity_origin    <date>         <int> <fct>     <fct>          <fct>    <fct>  1 2024-03-01        19 01009_AM  01001          0.5-2    frequent_activity  2 2024-03-01        15 01002     01001          10-50    frequent_activity dates_2 <- c(start = \"2023-02-14\", end = \"2023-02-17\") spod_download_data(type = \"od\", zones = \"distr\", dates = dates_2) db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = \"cached_v2\", save_format = \"duckdb\", overwrite = TRUE) db_2 # check the path to the saved `DuckDB` database dates_1 <- c(start = \"2020-02-17\", end = \"2020-02-19\") db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = dates_1, overwrite = TRUE) my_od_data_2 <- spod_connect(db_2) spod_disconnect(my_od_data_2) type <- \"od\" zones <- \"distr\" dates <- c(start = \"2020-02-14\", end = \"2020-02-17\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\") dates <- c(start = \"2020-02-16\", end = \"2020-02-19\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\", overwrite = 'update') my_od_data_3 <- spod_connect(od_parquet) my_od_data_3 |>    dplyr::distinct(date) |>   dplyr::arrange(date)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"duckdb","dir":"Articles","previous_headings":"","what":"DuckDB","title":"Download and convert OD datasets","text":"can convert already downloaded data DuckDB database. example, select dates, download data manually (note: use dates_2 refer fact using v2 data): , can convert downloaded data (including files might downloaded previosly running spod_get() spod_download_data() dates date intervals) DuckDB like (dates = \"cached_v2\" means use downloaded files): dates = \"cached_v2\" (can also dates = \"cached_v1\" v1 data) argument instructs function work already-downloaded files. default resulting DuckDB database v2 origin-destination data districts saved SPANISH_OD_DATA_DIR directory v2/tabular/duckdb/ filename od_distritos.duckdb (can change file path save_path argument). function returns full path database file, save db_2 variable. can also desired save location save_path argument spod_convert(). can also convert dates range dates list DuckDB: case, missing data now yet downloaded automatically downloaded, 2020-02-17 redownloaded, already requsted creating db_1. requested dates converted DuckDB, overwriting file db_1. , save path output DuckDB database file db_2 variable. can read introductory information connect DuckDB files , however simplify things created helper function. connect data stored path db_1 db_2 can following: Just like , spod_get() funciton used download raw CSV.gz files analyse without conversion, resulting object my_od_data_2 also tbl_duckdb_connection. , can treat regular data.frame tibble use dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. finishing working my_od_data_2 advise “disconnect” data using: useful free-memory neccessary like run spod_convert() save data location. Otherwise, also helpful avoid unnecessary possible warnings terminal garbage collected connections.","code":"dates_2 <- c(start = \"2023-02-14\", end = \"2023-02-17\") spod_download_data(type = \"od\", zones = \"distr\", dates = dates_2) db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = \"cached_v2\", save_format = \"duckdb\", overwrite = TRUE) db_2 # check the path to the saved `DuckDB` database dates_1 <- c(start = \"2020-02-17\", end = \"2020-02-19\") db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = dates_1, overwrite = TRUE) my_od_data_2 <- spod_connect(db_2) spod_disconnect(my_od_data_2)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"convert-to-duckdb","dir":"Articles","previous_headings":"2 Getting a single day with spod_get()","what":"Convert to DuckDB","title":"Download and convert OD datasets","text":"can convert already downloaded data DuckDB database. example, select dates, download data manually (note: use dates_2 refer fact using v2 data): , can convert downloaded data (including files might downloaded previosly running spod_get() spod_download_data() dates date intervals) DuckDB like (dates = \"cached_v2\" means use downloaded files): dates = \"cached_v2\" (can also dates = \"cached_v1\" v1 data) argument instructs function work already-downloaded files. default resulting DuckDB database v2 origin-destination data districts saved SPANISH_OD_DATA_DIR directory v2/tabular/duckdb/ filename od_distritos.duckdb (can change file path save_path argument). function returns full path database file, save db_2 variable. can also desired save location save_path argument spod_convert(). can also convert dates range dates list DuckDB: case, missing data now yet downloaded automatically downloaded, 2020-02-17 redownloaded, already requsted creating db_1. requested dates converted DuckDB, overwriting file db_1. , save path output DuckDB database file db_2 variable.","code":"dates_2 <- c(start = \"2023-02-14\", end = \"2023-02-17\") spod_download_data(type = \"od\", zones = \"distr\", dates = dates_2) db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = \"cached_v2\", save_format = \"duckdb\", overwrite = TRUE) db_2 # check the path to the saved `DuckDB` database dates_1 <- c(start = \"2020-02-17\", end = \"2020-02-19\") db_2 <- spod_convert(type = \"od\", zones = \"distr\", dates = dates_1, overwrite = TRUE)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"load-converted-duckdb","dir":"Articles","previous_headings":"2 Getting a single day with spod_get()","what":"Load the converted DuckDB","title":"Download and convert OD datasets","text":"can read introductory information connect DuckDB files , however simplify things created helper function. connect data stored path db_1 db_2 can following: Just like , spod_get() funciton used download raw CSV.gz files analyse without conversion, resulting object my_od_data_2 also tbl_duckdb_connection. , can treat regular data.frame tibble use dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. finishing working my_od_data_2 advise “disconnect” data using: useful free-memory neccessary like run spod_convert() save data location. Otherwise, also helpful avoid unnecessary possible warnings terminal garbage collected connections.","code":"my_od_data_2 <- spod_connect(db_2) spod_disconnect(my_od_data_2)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"arrow-parquet","dir":"Articles","previous_headings":"","what":"Parquet","title":"Download and convert OD datasets","text":"process exactly DuckDB . difference data converted parquet format stored SPANISH_OD_DATA_DIR v1/clean_data/tabular/parquet/ directory v1 data (change save_path argument), subfolders hive-style format like year=2020/month=2/day=14 inside folders single parquet file placed containing data day. advantage format can “update” quickly. example, first downloaded data March April 2020, converted period parquet format, downloaded data May June 2020, run convertion function , convert data May June 2020 add existing parquet files. save time wait March April 2020 converted . Let us convert dates parquet format: now request additional dates overlap already converted data like specifiy argument overwrite = 'update' update existing parquet files new data: , 16 17 Feboruary converted . new data, converted (18 19 February) converted, added existing folder structure ofparquet files stored default save_path location, <data_dir>/clean_data/v1/tabular/parquet/od_distritos. Alternatively, can set save location setting save_path argument. Working parquet files exactly DuckDB Arrow files. Just like , can use helper function spod_connect() connect parquet files: Mind though, first converted data period 14 17 February 2020, converted data period 16 19 February 2020 save default location, od_parquet contains path data, therefore my_od_data_3 connect data. can check like : prepare origin-destination data v1 (2020-2021) analysis whole period data availability, please follow steps :","code":"type <- \"od\" zones <- \"distr\" dates <- c(start = \"2020-02-14\", end = \"2020-02-17\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\") dates <- c(start = \"2020-02-16\", end = \"2020-02-19\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\", overwrite = 'update') my_od_data_3 <- spod_connect(od_parquet) my_od_data_3 |>    dplyr::distinct(date) |>   dplyr::arrange(date)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"convert-to-parquet","dir":"Articles","previous_headings":"2 Getting a single day with spod_get()","what":"Convert to Parquet","title":"Download and convert OD datasets","text":"Let us convert dates parquet format: now request additional dates overlap already converted data like specifiy argument overwrite = 'update' update existing parquet files new data: , 16 17 Feboruary converted . new data, converted (18 19 February) converted, added existing folder structure ofparquet files stored default save_path location, <data_dir>/clean_data/v1/tabular/parquet/od_distritos. Alternatively, can set save location setting save_path argument.","code":"type <- \"od\" zones <- \"distr\" dates <- c(start = \"2020-02-14\", end = \"2020-02-17\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\") dates <- c(start = \"2020-02-16\", end = \"2020-02-19\") od_parquet <- spod_convert(type = type, zones = zones, dates = dates, save_format = \"parquet\", overwrite = 'update')"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"load-converted-parquet","dir":"Articles","previous_headings":"2 Getting a single day with spod_get()","what":"Load the converted Parquet","title":"Download and convert OD datasets","text":"Working parquet files exactly DuckDB Arrow files. Just like , can use helper function spod_connect() connect parquet files: Mind though, first converted data period 14 17 February 2020, converted data period 16 19 February 2020 save default location, od_parquet contains path data, therefore my_od_data_3 connect data. can check like : prepare origin-destination data v1 (2020-2021) analysis whole period data availability, please follow steps :","code":"my_od_data_3 <- spod_connect(od_parquet) my_od_data_3 |>    dplyr::distinct(date) |>   dplyr::arrange(date)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"all-dates","dir":"Articles","previous_headings":"","what":"Download all available data","title":"Download and convert OD datasets","text":"Due mobile network outages, dates missing, assume simple interval two dates just work. Currently known outages : 26, 27, 30, 31 October, 1, 2 3 November 2023 4, 18, 19 April 2024. adviseable use spod_get_valid_dates() function get possible dates available data. example origin-destination district level v1 data. can change type “number_of_trips” zones “municipalities” v1 data. v2 data, just use dates starting 2022-01-01 dates_v2 . Use function arguments v2 way shown v1, also consult v2 data codebook, many datasets addition “origin-destination” “number_of_trips”. TODO: insert link v2 codebook done. convert downloaded data DuckDB format lightning fast analysis. can change save_format parquet want save data Parquet format. comparison overview two formats please see Converting data DuckDB/Parquet faster analysis. default, spod_convert_data() save converted data SPANISH_OD_DATA_DIR directory. can change save_path argument spod_convert_data() want save data different location. conversion, 4 GB operating memory enough, speed process depends number processor cores speed disk storage. SSD preferred. default, spod_convert_data() use except one processor cores computer. can adjust max_n_cpu argument spod_convert_data(). can also increase maximum amount memory used max_mem_gb argument, makes difference analysis stage. Finally, analysis_data_storage simply store path converted data. Either path DuckDB database file path folder Parquet files. reference, converting whole v1 origin-destination data DuckDB takes 20 minutes 4 GB memory 3 processor cores. final size DuckDB database 18 GB, Parquet format - 26 GB. raw CSV files gzip archives 20GB. v2 data much larger, origin-destination tables 2022 - mid-2024 taking 150+ GB raw CSV.gz format. can pass analysis_data_storage path spod_connect() function, whether DuckDB Parquet. function determine data type automatically give back tbl_duckdb_connection1. Compared conversion process, might want increase available memory analysis step. , better. can control max_mem_gb argument. can manipulate my_data using dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. end sequence commands need add collect() execute whole chain data manipulations load results memory R data.frame/tibble. finishing working my_data advise “disconnect” free memory:","code":"dates_v1 <- spod_get_valid_dates(ver = 1) dates_v2 <- spod_get_valid_dates(ver = 2) type <- \"origin-destination\" zones <- \"districts\" spod_download_data(   type = type,   zones = zones,   dates = dates_v1,   return_output = FALSE, # to avoid getting all downloaded files printed to console   max_download_size_gb = 50 # in Gb, this should be well over the actual download size for v1 data ) save_format <- \"duckdb\"  analysis_data_storage <- spod_convert_data(   type = type,   zones = zones,   dates = \"cached_v1\", # to just convert all data that was previously downloaded, no need to specify dates here   save_format = save_format,   overwrite = TRUE ) my_data <- spod_connect(   data_path = analysis_data_storage,    max_mem_gb = 16 # in GB, set more if you have more, the more, the better. ) spod_disconnect(my_data)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"download-all-data","dir":"Articles","previous_headings":"","what":"Download all data","title":"Download and convert OD datasets","text":"example origin-destination district level v1 data. can change type “number_of_trips” zones “municipalities” v1 data. v2 data, just use dates starting 2022-01-01 dates_v2 . Use function arguments v2 way shown v1, also consult v2 data codebook, many datasets addition “origin-destination” “number_of_trips”. TODO: insert link v2 codebook done.","code":"type <- \"origin-destination\" zones <- \"districts\" spod_download_data(   type = type,   zones = zones,   dates = dates_v1,   return_output = FALSE, # to avoid getting all downloaded files printed to console   max_download_size_gb = 50 # in Gb, this should be well over the actual download size for v1 data )"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"convert-all-data-into-analysis-ready-format","dir":"Articles","previous_headings":"","what":"Convert all data into analysis ready format","title":"Download and convert OD datasets","text":"convert downloaded data DuckDB format lightning fast analysis. can change save_format parquet want save data Parquet format. comparison overview two formats please see Converting data DuckDB/Parquet faster analysis. default, spod_convert_data() save converted data SPANISH_OD_DATA_DIR directory. can change save_path argument spod_convert_data() want save data different location. conversion, 4 GB operating memory enough, speed process depends number processor cores speed disk storage. SSD preferred. default, spod_convert_data() use except one processor cores computer. can adjust max_n_cpu argument spod_convert_data(). can also increase maximum amount memory used max_mem_gb argument, makes difference analysis stage. Finally, analysis_data_storage simply store path converted data. Either path DuckDB database file path folder Parquet files.","code":"save_format <- \"duckdb\"  analysis_data_storage <- spod_convert_data(   type = type,   zones = zones,   dates = \"cached_v1\", # to just convert all data that was previously downloaded, no need to specify dates here   save_format = save_format,   overwrite = TRUE )"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"conversion-speed","dir":"Articles","previous_headings":"","what":"Conversion speed","title":"Download and convert OD datasets","text":"reference, converting whole v1 origin-destination data DuckDB takes 20 minutes 4 GB memory 3 processor cores. final size DuckDB database 18 GB, Parquet format - 26 GB. raw CSV files gzip archives 20GB. v2 data much larger, origin-destination tables 2022 - mid-2024 taking 150+ GB raw CSV.gz format.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/articles/convert.html","id":"connecting-to-and-analysing-converted-datasets","dir":"Articles","previous_headings":"","what":"Connecting to and analysing converted datasets","title":"Download and convert OD datasets","text":"can pass analysis_data_storage path spod_connect() function, whether DuckDB Parquet. function determine data type automatically give back tbl_duckdb_connection1. Compared conversion process, might want increase available memory analysis step. , better. can control max_mem_gb argument. can manipulate my_data using dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. end sequence commands need add collect() execute whole chain data manipulations load results memory R data.frame/tibble. finishing working my_data advise “disconnect” free memory:","code":"my_data <- spod_connect(   data_path = analysis_data_storage,    max_mem_gb = 16 # in GB, set more if you have more, the more, the better. ) spod_disconnect(my_data)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/uses.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Use cases","text":"vignette serves place showcase use cases package. ’ll start loading week’s worth origin-destination data city Salamanca, building example README (note: chunks evaluated):","code":"od_db <- spod_get(   type = \"od\",   zones = \"distritos\",   dates = c(start = \"2024-03-01\", end = \"2024-03-07\") ) distritos <- spod_get_zones(\"distritos\", ver = 2) distritos_wgs84 <- distritos |>   sf::st_simplify(dTolerance = 200) |>   sf::st_transform(4326) od_national_aggregated <- od_db |>   group_by(id_origin, id_destination) |>   summarise(Trips = sum(n_trips), .groups = \"drop\") |>   filter(Trips > 500) |>   collect() |>   arrange(desc(Trips)) od_national_aggregated od_national_interzonal <- od_national_aggregated |>   filter(id_origin != id_destination) salamanca_zones <- zonebuilder::zb_zone(\"Salamanca\") distritos_salamanca <- distritos_wgs84[salamanca_zones, ] ids_salamanca <- distritos_salamanca$id od_salamanca <- od_national_interzonal |>   filter(id_origin %in% ids_salamanca) |>   filter(id_destination %in% ids_salamanca) |>   arrange(Trips) od_salamanca_sf <- od::od_to_sf(   od_salamanca,   z = distritos_salamanca )"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/uses.html","id":"disaggregating-desire-lines","dir":"Articles","previous_headings":"","what":"Disaggregating desire lines","title":"Use cases","text":"’ll need additional dependencies: ’ll get road network OSM:  can use road network disaggregate desire lines: Let’s plot disaggregated desire lines:  results show can add value OD data disaggregating desire lines odjitter package. can useful understanding spatial distribution trips within zone transport planning. plotted disaggregated desire lines top major road network Salamanca. next step routing help prioritise infrastructure improvements.","code":"remotes::install_github(\"dabreegster/odjitter\", subdir = \"r\") remotes::install_github(\"nptscot/osmactive\") salamanca_boundary <- sf::st_union(distritos_salamanca) osm_full <- osmactive::get_travel_network(salamanca_boundary) osm <- osm_full[salamanca_boundary, ] drive_net <- osmactive::get_driving_network(osm) drive_net_major <- osmactive::get_driving_network_major(osm) cycle_net <- osmactive::get_cycling_network(osm) cycle_net <- osmactive::distance_to_road(cycle_net, drive_net_major) cycle_net <- osmactive::classify_cycle_infrastructure(cycle_net) map_net <- osmactive::plot_osm_tmap(cycle_net) map_net od_jittered <- odjitter::jitter(   od_salamanca_sf,   zones = distritos_salamanca,   subpoints = drive_net,   disaggregation_threshold = 1000,   disaggregation_key = \"Trips\" ) od_jittered |>   arrange(Trips) |>   ggplot() +   geom_sf(aes(colour = Trips), size = 1) +   scale_colour_viridis_c() +   geom_sf(data = drive_net_major, colour = \"black\") +   theme_void()"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"overall-approach-to-working-with-data","dir":"Articles","previous_headings":"","what":"Overall approach to working with data","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"want analyse data days, can use spod_get() function. download raw data CSV format let analyse -memory. cover steps page. need longer periods (several months years), use spod_convert() spod_connect() functions, convert data special format much faster analysis, see Download convert OD datasets vignette. spod_get_zones() give spatial data zones can matched origin-destination flows functions using zones ’id’s. Please see simple example , also consult vignettes detailed data description instructions package vignettes spod_codebook(ver = 1) spod_codebook(ver = 2), simply visit package website https://robinlovelace.github.io/spanishoddata/. Figure 1 presents overall approach accessing data spanishoddata package. Figure 1: overview use pacakge functions get data","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"spatial-data-with-zoning-boundaries","dir":"Articles","previous_headings":"","what":"1. Spatial data with zoning boundaries","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"boundary data provided two geographic levels: Distrtics Municipalities. ’s important note always align official Spanish census districts municipalities. comply data protection regulations, certain aggregations made districts municipalities” Districts correspond official census districts cities; however, lower population density, grouped together. rural areas, one district often equal municipality, municipalities low population combined larger units preserve privacy individuals dataset. Therefore, 2850 ‘districts’ compared 10494 official census districts based. access : districts_v1 object class sf consisting polygons. Data structure: Municipalities made official municipalities certain size; however, also aggregated cases lower population density. result, 2,205 municipalities compared 8,125 official municipalities based. access : resulting municipalities_v1 object type sf consisting polygons. Data structure: spatial data get via spanishoddata package downloaded directly source, geometries polygons automatically fixed invalid geometries. zone identifiers stored id column. Apart id column, original zones files metadata. However, seen , using spanishoddata package get many additional columns provide semantic connection official statistical zones used Spanish government zones can get v2 data (2022 onward).","code":"districts_v1 <- spod_get_zones(\"dist\", ver = 1) municipalities_v1 <- spod_get_zones(\"muni\", ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"districts","dir":"Articles","previous_headings":"","what":"1.1 Districts","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"Districts correspond official census districts cities; however, lower population density, grouped together. rural areas, one district often equal municipality, municipalities low population combined larger units preserve privacy individuals dataset. Therefore, 2850 ‘districts’ compared 10494 official census districts based. access : districts_v1 object class sf consisting polygons. Data structure:","code":"districts_v1 <- spod_get_zones(\"dist\", ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"municipalities","dir":"Articles","previous_headings":"","what":"1.2 Municipalities","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"Municipalities made official municipalities certain size; however, also aggregated cases lower population density. result, 2,205 municipalities compared 8,125 official municipalities based. access : resulting municipalities_v1 object type sf consisting polygons. Data structure: spatial data get via spanishoddata package downloaded directly source, geometries polygons automatically fixed invalid geometries. zone identifiers stored id column. Apart id column, original zones files metadata. However, seen , using spanishoddata package get many additional columns provide semantic connection official statistical zones used Spanish government zones can get v2 data (2022 onward).","code":"municipalities_v1 <- spod_get_zones(\"muni\", ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"mobility-data","dir":"Articles","previous_headings":"","what":"2. Mobility data","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"mobility data referenced via id_origin, id_destination, location identifiers (mostly labelled id) two sets zones described . origin-destination data contain number trips districts municipalities Spain every hour every day 2020-02-14 2021-05-09. flow also attributes trip purpose (composed type activity (home/work_or_study/) origin destination), province residence individuals making trip, distance covered making trip. See detailed attributes table. Figure 2 shows example total flows province Barcelona Feb 14th, 2020. Figure 2: Origin destination flows Barcelona 2020-02-14 variables can find district municipality level origin-destination data: original data stored maestra-2 folder suffixes distritos (district zoning) municipios (municipality zoning). use district level data several data issues municipality data documented , also distric level data contains columns useful origin-destination flow characteristics. result, get district level data municipality level data columns. Municipality level data simply re-aggregation district level data using official relations file district identifiers mapped municipality identifiers (orginal file relaciones_distrito_mitma.csv). Getting data access data, use spod_get_od() function. example use short interval dates: data specified dates automatically downloaded cached SPANISH_OD_DATA_DIR directory. Existing files re-downloaded. Working data resulting objects od_dist od_muni class tbl_duckdb_connection1. Basically, can treat regular data.frames tibbles. One important difference data actually loaded memory, requested dates, e.g. whole month year, data likely fit computer’s memory. tbl_duckdb_connection mapped downloaded CSV files cached disk data loaded small chunks needed time computation. can manipulate od_dist od_muni using dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. end sequence commands need add collect() execute whole chain data manipulations load results memory R data.frame/tibble like : example , calculated mean hourly flows 4 days requested period. full data 4 days never loaded memory . Rather available memory computer used maximum limit make calculation happen, without ever exceeding available memory limit. done transparantly user help DuckDB (specifically, {duckdb} R package Mühleisen Raasveldt (2024)). summary operation provided example can done entire dataset full 18 month regular laptop 8-16 GB memory. take bit time complete, done. speed things , also demonstrate end document, data can converted efficient formats. Note: long use object od_dist created spod_get_od() function, much quicker filter dates year, month day variables, rather date variable. data day separate CSV file located folders look like year=2020/month=2/day=14. filtering date field, R scan CSV files comparing specified date stored inside file. However, query year, month day variables, R needs check path CSV file, much quicker. caveat relevant long use spod_get_od() . convert (see relevant section ) downloaded data format optimized quick analysis, can use whichever field want, affect performance much. “number trips” data shows number individuals district municipality made trips categorised number trips. original data stored maestra-2 folder suffixes distritos (district zoning) municipios (municipality zoning). use district level data several data issues municipality data documented , also distric level data contains columns useful origin-destination flow characteristics. result, get district level data municipality level data columns. Municipality level data simply re-aggregation district level data using official relations file district identifiers mapped municipality identifiers (orginal file relaciones_distrito_mitma.csv). Getting data access use spod_get() type set “number_of_tripss”, just “nt”. can also set dates maximum possible date range 2020-02-14 2021-05-09 get data, data relatively small (200 Mb). data small, can actually load completely memory:","code":"dates <- c(start = \"2020-02-14\", end = \"2020-02-17\") od_dist <- spod_get(type = \"od\", zones = \"dist\", dates = dates) od_muni <- spod_get(type = \"od\", zones = \"muni\", dates = dates) library(dplyr) od_mean_hourly_trips_over_the_4_days <- od_dist |>   group_by(time_slot) |>   summarise(     mean_hourly_trips = mean(n_trips, na.rm = TRUE),     .groups = \"drop\") |>    collect() od_mean_hourly_trips_over_the_4_days # A tibble: 24 × 2    time_slot mean_hourly_trips        <int>             <dbl>  1        18              21.4  2        10              19.3  3         2              14.8  4        15              19.8  5        11              19.9  6        16              19.6  7        22              20.9  8         0              18.6  9        13              21.1 10        19              22.5 # ℹ 14 more rows # ℹ Use `print(n = ...)` to see more rows dates <- c(start = \"2020-02-14\", end = \"2021-05-09\") tpp_dist <- spod_get(type = \"number_of_trips\", zones = \"dist\", dates = dates) tpp_dist_tbl <- tpp_dist |> dplyr::collect()"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"od-data","dir":"Articles","previous_headings":"","what":"2.1. Origin-destination data","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"origin-destination data contain number trips districts municipalities Spain every hour every day 2020-02-14 2021-05-09. flow also attributes trip purpose (composed type activity (home/work_or_study/) origin destination), province residence individuals making trip, distance covered making trip. See detailed attributes table. Figure 2 shows example total flows province Barcelona Feb 14th, 2020. Figure 2: Origin destination flows Barcelona 2020-02-14 variables can find district municipality level origin-destination data: original data stored maestra-2 folder suffixes distritos (district zoning) municipios (municipality zoning). use district level data several data issues municipality data documented , also distric level data contains columns useful origin-destination flow characteristics. result, get district level data municipality level data columns. Municipality level data simply re-aggregation district level data using official relations file district identifiers mapped municipality identifiers (orginal file relaciones_distrito_mitma.csv). Getting data access data, use spod_get_od() function. example use short interval dates: data specified dates automatically downloaded cached SPANISH_OD_DATA_DIR directory. Existing files re-downloaded. Working data resulting objects od_dist od_muni class tbl_duckdb_connection1. Basically, can treat regular data.frames tibbles. One important difference data actually loaded memory, requested dates, e.g. whole month year, data likely fit computer’s memory. tbl_duckdb_connection mapped downloaded CSV files cached disk data loaded small chunks needed time computation. can manipulate od_dist od_muni using dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. end sequence commands need add collect() execute whole chain data manipulations load results memory R data.frame/tibble like : example , calculated mean hourly flows 4 days requested period. full data 4 days never loaded memory . Rather available memory computer used maximum limit make calculation happen, without ever exceeding available memory limit. done transparantly user help DuckDB (specifically, {duckdb} R package Mühleisen Raasveldt (2024)). summary operation provided example can done entire dataset full 18 month regular laptop 8-16 GB memory. take bit time complete, done. speed things , also demonstrate end document, data can converted efficient formats. Note: long use object od_dist created spod_get_od() function, much quicker filter dates year, month day variables, rather date variable. data day separate CSV file located folders look like year=2020/month=2/day=14. filtering date field, R scan CSV files comparing specified date stored inside file. However, query year, month day variables, R needs check path CSV file, much quicker. caveat relevant long use spod_get_od() . convert (see relevant section ) downloaded data format optimized quick analysis, can use whichever field want, affect performance much.","code":"dates <- c(start = \"2020-02-14\", end = \"2020-02-17\") od_dist <- spod_get(type = \"od\", zones = \"dist\", dates = dates) od_muni <- spod_get(type = \"od\", zones = \"muni\", dates = dates) library(dplyr) od_mean_hourly_trips_over_the_4_days <- od_dist |>   group_by(time_slot) |>   summarise(     mean_hourly_trips = mean(n_trips, na.rm = TRUE),     .groups = \"drop\") |>    collect() od_mean_hourly_trips_over_the_4_days # A tibble: 24 × 2    time_slot mean_hourly_trips        <int>             <dbl>  1        18              21.4  2        10              19.3  3         2              14.8  4        15              19.8  5        11              19.9  6        16              19.6  7        22              20.9  8         0              18.6  9        13              21.1 10        19              22.5 # ℹ 14 more rows # ℹ Use `print(n = ...)` to see more rows"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"tpp-data","dir":"Articles","previous_headings":"","what":"2.2. Number of trips data","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"“number trips” data shows number individuals district municipality made trips categorised number trips. original data stored maestra-2 folder suffixes distritos (district zoning) municipios (municipality zoning). use district level data several data issues municipality data documented , also distric level data contains columns useful origin-destination flow characteristics. result, get district level data municipality level data columns. Municipality level data simply re-aggregation district level data using official relations file district identifiers mapped municipality identifiers (orginal file relaciones_distrito_mitma.csv). Getting data access use spod_get() type set “number_of_tripss”, just “nt”. can also set dates maximum possible date range 2020-02-14 2021-05-09 get data, data relatively small (200 Mb). data small, can actually load completely memory:","code":"dates <- c(start = \"2020-02-14\", end = \"2021-05-09\") tpp_dist <- spod_get(type = \"number_of_trips\", zones = \"dist\", dates = dates) tpp_dist_tbl <- tpp_dist |> dplyr::collect()"},{"path":"https://robinlovelace.github.io/spanishoddata/articles/v1-2020-2021-mitma-data-codebook.html","id":"advanced-use","dir":"Articles","previous_headings":"","what":"Advanced use","title":"Codebook and cookbook for v1 (2020-2021) Spanish mobility data","text":"advanced use, especially analysing longer periods (months even years), please see Download convert OD datasets.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Egor Kotov. Author, maintainer. Robin Lovelace. Author. Eugeni Vidal-Tortosa. Contributor.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kotov E, Lovelace R (2024). spanishoddata: Get Spanish Origin-Destination Data. R package version 0.0.1, https://github.com/Robinlovelace/spanishoddata, https://robinlovelace.github.io/spanishoddata/.","code":"@Manual{,   title = {spanishoddata: Get Spanish Origin-Destination Data},   author = {Egor Kotov and Robin Lovelace},   year = {2024},   note = {R package version 0.0.1,     https://github.com/Robinlovelace/spanishoddata},   url = {https://robinlovelace.github.io/spanishoddata/}, }"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"installation","dir":"","previous_headings":"","what":"Get Spanish Origin-Destination Data","title":"Get Spanish Origin-Destination Data","text":"package yet available CRAN. Install development version package follows: Load follows: load package locally, clone navigate root package terminal, e.g. following: run following command R console:","code":"if (!require(\"remotes\")) install.packages(\"remotes\") remotes::install_github(\"Robinlovelace/spanishoddata\",   force = TRUE, dependencies = TRUE) library(spanishoddata) gh repo clone Robinlovelace/spanishoddata code spanishoddata # with rstudio: rstudio spanishoddata/spanishoddata.Rproj devtools::load_all()"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"setting-the-data-directory","dir":"","previous_headings":"","what":"Setting the data directory","title":"Get Spanish Origin-Destination Data","text":"Choose spanishoddata download (convert) data setting SPANISH_OD_DATA_DIR environment variable following command: package create directory exist first run function downloads data. can specify data directory globally setting SPANISH_OD_DATA_DIR environment variable, e.g. following command: can also set data directory locally per session basis described . Set ‘envar’ working directory editing .Renviron file root project: Finally, can set data directory current R session follows:","code":"Sys.setenv(SPANISH_OD_DATA_DIR = \"/path/to/data\") usethis::edit_r_environ() # Then set the data directory globally, by typing this line in the file: SPANISH_OD_DATA_DIR = \"/path/to/data\" file.edit(\".Renviron\") Sys.setenv(SPANISH_OD_DATA_DIR = \"/path/to/data\")"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"using-the-package","dir":"","previous_headings":"","what":"Using the package","title":"Get Spanish Origin-Destination Data","text":"can find overview key package functions following figure.  want analyse data days, can use spod_get() function. download raw data CSV format let analyse -memory. need longer periods (several months years), use spod_convert() spod_connect() functions, convert data special format much faster analysis. spod_get_zones() give spatial data zones can matched origin-destination flows functions using zones ’id’s. Please see simple example , also consult vignettes detailed data description instructions package vignettes spod_codebook(ver = 1) spod_codebook(ver = 2), simply visit package website https://robinlovelace.github.io/spanishoddata/.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"showcase","dir":"","previous_headings":"","what":"Showcase","title":"Get Spanish Origin-Destination Data","text":"run code README use following setup: Get metadata datasets follows (using version 2 data covering years 2022 onwards):","code":"library(tidyverse) theme_set(theme_minimal()) sf::sf_use_s2(FALSE) metadata <- spod_available_data(ver = 2) # for version 2 of the data metadata # A tibble: 9,442 × 6    target_url           pub_ts              file_extension data_ym data_ymd      <chr>                <dttm>              <chr>          <date>  <date>      1 https://movilidad-o… 2024-07-30 10:54:08 gz             NA      2022-10-23  2 https://movilidad-o… 2024-07-30 10:51:07 gz             NA      2022-10-22  3 https://movilidad-o… 2024-07-30 10:47:52 gz             NA      2022-10-20  4 https://movilidad-o… 2024-07-30 10:14:55 gz             NA      2022-10-18  5 https://movilidad-o… 2024-07-30 10:11:58 gz             NA      2022-10-17  6 https://movilidad-o… 2024-07-30 10:09:03 gz             NA      2022-10-12  7 https://movilidad-o… 2024-07-30 10:05:57 gz             NA      2022-10-07  8 https://movilidad-o… 2024-07-30 10:02:12 gz             NA      2022-08-07  9 https://movilidad-o… 2024-07-30 09:58:34 gz             NA      2022-08-06 10 https://movilidad-o… 2024-07-30 09:54:30 gz             NA      2022-08-05 # ℹ 9,432 more rows # ℹ 1 more variable: local_path <chr>"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"zones","dir":"","previous_headings":"","what":"Zones","title":"Get Spanish Origin-Destination Data","text":"Zones can downloaded follows:","code":"distritos <- spod_get_zones(\"distritos\", ver = 2) distritos_wgs84 <- distritos |>   sf::st_simplify(dTolerance = 200) |>   sf::st_transform(4326) plot(sf::st_geometry(distritos_wgs84))"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"od-data","dir":"","previous_headings":"","what":"OD data","title":"Get Spanish Origin-Destination Data","text":"result R database interface object (tbl_dbi) can used dplyr functions SQL queries ‘lazily’, meaning data loaded memory needed. Let’s aggregation find total number trips per hour 7 days:  figure summarises 925,874,012 trips 7 days associated 135,866,524 records.","code":"od_db <- spod_get(   type = \"origin-destination\",   zones = \"districts\",   dates = c(start = \"2024-03-01\", end = \"2024-03-07\") ) class(od_db) [1] \"tbl_duckdb_connection\" \"tbl_dbi\"               \"tbl_sql\"               [4] \"tbl_lazy\"              \"tbl\" colnames(od_db) [1] \"full_date\"                   \"time_slot\"                    [3] \"id_origin\"                   \"id_destination\"               [5] \"distance\"                    \"activity_origin\"              [7] \"activity_destination\"        \"study_possible_origin\"        [9] \"study_possible_destination\"  \"residence_province_ine_code\" [11] \"residence_province\"          \"income\"                      [13] \"age\"                         \"sex\"                         [15] \"n_trips\"                     \"trips_total_length_km\"       [17] \"year\"                        \"month\"                       [19] \"day\" n_per_hour <- od_db |>   group_by(date, time_slot) |>   summarise(n = n(), Trips = sum(n_trips)) |>   collect() |>   mutate(Time = lubridate::ymd_h(paste0(date, time_slot, sep = \" \"))) |>   mutate(Day = lubridate::wday(Time, label = TRUE)) n_per_hour |>   ggplot(aes(x = Time, y = Trips)) +   geom_line(aes(colour = Day)) +   labs(title = \"Number of trips per hour over 7 days\")"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"spanishoddata-advantage-over-accessing-the-data-yourself","dir":"","previous_headings":"","what":"spanishoddata advantage over accessing the data yourself","title":"Get Spanish Origin-Destination Data","text":"demonstrated , can perform quick analysis using just lines code. highlight benefits package, manually: download xml file download links parse xml extract download links write script download files locate disk logical manner figure data structure downloaded files, read codebook translate data (columns values) English, familiar Spanish write script load data database figure way claculate summaries multiple files much … present simple functions get straight data one line code, ready run analysis .","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"desire-lines","dir":"","previous_headings":"","what":"Desire lines","title":"Get Spanish Origin-Destination Data","text":"’ll use input data pick-important flows Spain, focus longer trips visualisation: results show largest flows intra-zonal. Let’s keep inter-zonal flows: can convert geographic data {od} package (Lovelace Morgan 2024):  Let’s focus trips around particular area (Salamanca):  use information subset rows, capture movement within study area: Let’s plot results:","code":"od_national_aggregated <- od_db |>   group_by(id_origin, id_destination) |>   summarise(Trips = sum(n_trips), .groups = \"drop\") |>   filter(Trips > 500) |>   collect() |>   arrange(desc(Trips)) od_national_aggregated # A tibble: 96,404 × 3    id_origin id_destination    Trips    <fct>     <fct>             <dbl>  1 2807908   2807908        2441404.  2 0801910   0801910        2112188.  3 0801902   0801902        2013618.  4 2807916   2807916        1821504.  5 2807911   2807911        1785981.  6 04902     04902          1690606.  7 2807913   2807913        1504484.  8 2807910   2807910        1299586.  9 0704004   0704004        1287122. 10 28106     28106          1286058. # ℹ 96,394 more rows od_national_interzonal <- od_national_aggregated |>   filter(id_origin != id_destination) od_national_sf <- od::od_to_sf(   od_national_interzonal,   z = distritos_wgs84 ) distritos_wgs84 |>   ggplot() +   geom_sf(aes(fill = population)) +   geom_sf(data = spData::world, fill = NA, colour = \"black\") +   geom_sf(aes(size = Trips), colour = \"blue\", data = od_national_sf) +   coord_sf(xlim = c(-10, 5), ylim = c(35, 45)) +   theme_void() salamanca_zones <- zonebuilder::zb_zone(\"Salamanca\") distritos_salamanca <- distritos_wgs84[salamanca_zones, ] plot(distritos_salamanca) ids_salamanca <- distritos_salamanca$id od_salamanca <- od_national_sf |>   filter(id_origin %in% ids_salamanca) |>   filter(id_destination %in% ids_salamanca) |>   arrange(Trips) od_salamanca_sf <- od::od_to_sf(   od_salamanca,   z = distritos_salamanca ) ggplot() +   geom_sf(fill = \"grey\", data = distritos_salamanca) +   geom_sf(aes(colour = Trips), size = 1, data = od_salamanca_sf) +   scale_colour_viridis_c() +   theme_void()"},{"path":"https://robinlovelace.github.io/spanishoddata/index.html","id":"further-information","dir":"","previous_headings":"","what":"Further information","title":"Get Spanish Origin-Destination Data","text":"information package, see: Information functions v1 vs v2 vignette explains differences two versions data uses vignette documents use cases","code":""},{"path":[]},{"path":"https://robinlovelace.github.io/spanishoddata/reference/global_quiet_param.html","id":null,"dir":"Reference","previous_headings":"","what":"Global Quiet Parameter — global_quiet_param","title":"Global Quiet Parameter — global_quiet_param","text":"Documentation quiet parameter, used globally.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/global_quiet_param.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global Quiet Parameter — global_quiet_param","text":"","code":"global_quiet_param(quiet = FALSE)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/global_quiet_param.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global Quiet Parameter — global_quiet_param","text":"quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available data list — spod_available_data","title":"Get available data list — spod_available_data","text":"Get table links available data files specified data version. Optionally check (see arguments) certain files already downloaded cache directory specified SPANISH_OD_DATA_DIR environment variable custom path specified data_dir argument.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available data list — spod_available_data","text":"","code":"spod_available_data(   ver = 2,   check_local_files = FALSE,   quiet = FALSE,   data_dir = spod_get_data_dir() )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get available data list — spod_available_data","text":"ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards. check_local_files Whether check local files exist. Defaults FALSE. quiet logical value indicating whether suppress messages. Default FALSE. data_dir directory data stored. Defaults value returned spod_get_data_dir().","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available data list — spod_available_data","text":"tibble links, release dates files data, dates data coverage, local paths files, download status. target_url character. URL link data file. pub_ts POSIXct. timestamp file published. file_extension character. file extension data file (e.g., 'tar', 'gz'). data_ym Date. year month data coverage, available. data_ymd Date. specific date data coverage, available. local_path character. local file path data stored. downloaded logical. Indicator whether data file downloaded locally.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v1.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the available v1 data list — spod_available_data_v1","title":"Get the available v1 data list — spod_available_data_v1","text":"function provides table available data list MITMA v1 (2020-2021), remote local.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the available v1 data list — spod_available_data_v1","text":"","code":"spod_available_data_v1(   data_dir = spod_get_data_dir(),   check_local_files = FALSE,   quiet = FALSE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the available v1 data list — spod_available_data_v1","text":"data_dir directory data stored. Defaults value returned spod_get_data_dir(). check_local_files Whether check local files exist. Defaults FALSE. quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the available v1 data list — spod_available_data_v1","text":"tibble links, release dates files data, dates data coverage, local paths files, download status. target_url character. URL link data file. pub_ts POSIXct. timestamp file published. file_extension character. file extension data file (e.g., 'tar', 'gz'). data_ym Date. year month data coverage, available. data_ymd Date. specific date data coverage, available. local_path character. local file path data stored. downloaded logical. Indicator whether data file downloaded locally.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the available v1 data list — spod_available_data_v1","text":"","code":"# Get the available v1 data list for the default data directory if (FALSE) {   metadata <- spod_available_data_v1()   names(metadata)   head(metadata) }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the data dictionary — spod_available_data_v2","title":"Get the data dictionary — spod_available_data_v2","text":"function retrieves data dictionary specified data directory.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the data dictionary — spod_available_data_v2","text":"","code":"spod_available_data_v2(   data_dir = spod_get_data_dir(),   check_local_files = FALSE,   quiet = FALSE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the data dictionary — spod_available_data_v2","text":"data_dir directory data stored. Defaults value returned spod_get_data_dir(). check_local_files Whether check local files exist. Defaults FALSE. quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the data dictionary — spod_available_data_v2","text":"tibble links, release dates files data, dates data coverage, local paths files, download status. target_url character. URL link data file. pub_ts POSIXct. timestamp file published. file_extension character. file extension data file (e.g., 'tar', 'gz'). data_ym Date. year month data coverage, available. data_ymd Date. specific date data coverage, available. local_path character. local file path data stored. downloaded logical. Indicator whether data file downloaded locally.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_data_v2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the data dictionary — spod_available_data_v2","text":"","code":"# Get the data dictionary for the default data directory if (FALSE) {   metadata <- spod_available_data_v2()   names(metadata)   head(metadata) }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_ram.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available RAM — spod_available_ram","title":"Get available RAM — spod_available_ram","text":"Get available RAM","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_ram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available RAM — spod_available_ram","text":"","code":"spod_available_ram()"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_available_ram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available RAM — spod_available_ram","text":"numeric amount available RAM GB.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v1.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v1","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v1","text":"function fixes invalid geometries zones data renames \"ID\" column \"id\".","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v1","text":"","code":"spod_clean_zones_v1(zones_path, zones)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v1","text":"zones_path path zones spatial data file. zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards).","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v1","text":"spatial object containing cleaned zones data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v2","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v2","text":"function fixes invalid geometries zones data renames \"ID\" column \"id\". also attacches population counts zone names provided csv files supplied original data provider.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v2","text":"","code":"spod_clean_zones_v2(zones_path)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v2","text":"zones_path path zones spatial data file.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_clean_zones_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fixes common issues in the zones data and cleans up variable names — spod_clean_zones_v2","text":"spatial object containing cleaned zones data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"View codebooks for v1 and v2 open mobility data — spod_codebook","title":"View codebooks for v1 and v2 open mobility data — spod_codebook","text":"Opens relevant vignette.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View codebooks for v1 and v2 open mobility data — spod_codebook","text":"","code":"spod_codebook(ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_codebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View codebooks for v1 and v2 open mobility data — spod_codebook","text":"ver integer numeric value. version data. Defaults 1. Can 1 v1 (2020-2021) data 2 v2 (2022 onwards) data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_codebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"View codebooks for v1 and v2 open mobility data — spod_codebook","text":"Nothing, calls relevant vignette.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_connect.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to data converted to DuckDB — spod_connect","title":"Connect to data converted to DuckDB — spod_connect","text":"function allows user quickly connect data converted DuckDB spod_convert_to_duckdb() function. function simplificaiton connection process. uses","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_connect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to data converted to DuckDB — spod_connect","text":"","code":"spod_connect(   data_path,   target_table_name = NULL,   quiet = FALSE,   max_mem_gb = max(4, spod_available_ram() - 4),   max_n_cpu = parallelly::availableCores() - 1,   temp_path = spod_get_temp_dir() )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_connect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to data converted to DuckDB — spod_connect","text":"data_path path DuckDB database file '.duckdb' extension, path folder parquet files. Eigher one created spod_convert() function. target_table_name table name inside database. quiet logical value indicating whether suppress messages. Default FALSE. max_mem_gb maximum memory use GB. conservative default 3 GB, enough resaving data DuckDB form folder CSV.gz files small enough fit memory even old computers. data analysis using already converted data (DuckDB Parquet format) raw CSV.gz data, recommended increase according available resources. max_n_cpu maximum number threads use. Defaults number available cores minus 1. temp_path path temp folder DuckDB intermediate spilling case set memory limit /physical memory computer low perform query. default set temp directory data folder defined SPANISH_OD_DATA_DIR environment variable. Otherwise, queries folders CSV files parquet files, temporary path set current R working directory, probably undesirable, current working directory can slow storage, storage may limited space, compared data folder.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_connect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to data converted to DuckDB — spod_connect","text":"DuckDB table connection object.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_convert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data from plain text to duckdb or parquet format — spod_convert","title":"Convert data from plain text to duckdb or parquet format — spod_convert","text":"Converts data faster analysis either DuckDB file parquet files hive-style directory structure. Running analysis files sometimes 100x times faster working raw CSV files, espetially gzip archives. connect converted data, please use mydata <- spod_connect() passing path data saved. connected mydata can analysed using dplyr functions select(), filter(), mutate(), group_by(), summarise(), etc. end sequence commands need add collect() execute whole chain data manipulations load results memory R data.frame/tibble. -depth usage data, please refer DuckDB documentation examples https://duckdb.org/docs/api/r#dbplyr . useful examples can found https://arrow-user2022.netlify.app/data-wrangling#combining-arrow--duckdb . may also use arrow package work parquet files https://arrow.apache.org/docs/r/.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_convert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data from plain text to duckdb or parquet format — spod_convert","text":"","code":"spod_convert(   type = c(\"od\", \"origin-destination\", \"os\", \"overnight_stays\", \"nt\", \"number_of_trips\"),   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\"),   dates = NULL,   save_format = \"duckdb\",   save_path = NULL,   overwrite = FALSE,   data_dir = spod_get_data_dir(),   quiet = FALSE,   max_mem_gb = max(4, spod_available_ram() - 4),   max_n_cpu = parallelly::availableCores() - 1,   max_download_size_gb = 1 )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_convert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data from plain text to duckdb or parquet format — spod_convert","text":"type type data download. Can \"origin-destination\" (ust \"od\"), \"number_of_trips\" (just \"nt\") v1 data. v2 data \"overnight_stays\" (just \"os\") also available. data types supported future. See respective codebooks information. ADD CODEBOOKS! package zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020. save_format character vector length 1 values \"duckdb\" \"parquet\". Defaults \"duckdb\". NULL automatically inferred save_path argument. save_format provided, save_path set default location set SPANISH_OD_DATA_DIR environment variable using Sys.setenv(SPANISH_OD_DATA_DIR = 'path///cache/dir')). v1 data path <data_dir>/clean_data/v1/tabular/duckdb/ <data_dir>/clean_data/v1/tabular/parquet/. can also set save_path. ends \".duckdb\", save DuckDB database format, save_path end \".duckdb\", save parquet format treat save_path path folder, file, create necessary hive-style subdirectories folder. Hive style looks like year=2020/month=2/day=14 inside directory data_0.parquet file contains data day. save_path character vector length 1. full (relative) path DuckDB database file parquet folder. save_path ends .duckdb, saved DuckDB database file. format argument automatically set save_format='duckdb'. save_path ends folder name (e.g. /data_dir/clean_data/v1/tabular/parquet/od_distr origin-destination data district level), data saved collection parquet files hive-style directory structure. subfolders od_distr year=2020/month=2/day=14 inside folders single parquet file placed containing data day. NULL, uses default location data_dir (set SPANISH_OD_DATA_DIR environment variable using Sys.setenv(SPANISH_OD_DATA_DIR = 'path///cache/dir')). Therefore, default relative path DuckDB <data_dir>/clean_data/v1/tabular/duckdb/<type>_<zones>.duckdb parquet files <data_dir>/clean_data/v1/tabular/parquet/<type>_<zones>/, type type data (e.g. 'od', 'os', 'tpp', etc.) zones name geographic zones (e.g. 'distr', 'muni', etc.). See details function arguments description. overwrite logical character vector length 1. TRUE, overwrites existing DuckDBorparquetfiles. Defaults toFALSE`. parquet files can also set 'update', parquet files created dates yet converted. data_dir directory data stored. Defaults value returned spod_get_data_dir() returns value environment variable SPANISH_OD_DATA_DIR temporary directory variable set. quiet logical value indicating whether suppress messages. Default FALSE. max_mem_gb maximum memory use GB. conservative default 3 GB, enough resaving data DuckDB form folder CSV.gz files small enough fit memory even old computers. data analysis using already converted data (DuckDB Parquet format) raw CSV.gz data, recommended increase according available resources. max_n_cpu maximum number threads use. Defaults number available cores minus 1. max_download_size_gb maximum download size gigabytes. Defaults 1.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_convert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data from plain text to duckdb or parquet format — spod_convert","text":"Path saved DuckDB file.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_dates_argument_to_dates_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert multiple formates of date arguments to a sequence of dates — spod_dates_argument_to_dates_seq","title":"Convert multiple formates of date arguments to a sequence of dates — spod_dates_argument_to_dates_seq","text":"function processes date arguments provided various functions package. can handle single dates arbitratry sequences (vectors) dates ISO (YYYY-MM-DD) YYYYMMDD format. can also handle date ranges format 'YYYY-MM-DD_YYYY-MM-DD' ('YYYYMMDD_YYYYMMDD'), date ranges named vec regular expressions match dates format YYYYMMDD.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_dates_argument_to_dates_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert multiple formates of date arguments to a sequence of dates — spod_dates_argument_to_dates_seq","text":"","code":"spod_dates_argument_to_dates_seq(dates)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_dates_argument_to_dates_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert multiple formates of date arguments to a sequence of dates — spod_dates_argument_to_dates_seq","text":"dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_dates_argument_to_dates_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert multiple formates of date arguments to a sequence of dates — spod_dates_argument_to_dates_seq","text":"character vector dates ISO format (YYYY-MM-DD).","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_disconnect.html","id":null,"dir":"Reference","previous_headings":"","what":"Safely disconnect from data and free memory — spod_disconnect","title":"Safely disconnect from data and free memory — spod_disconnect","text":"function ensure DuckDB connections CSV.gz files (created via spod_get()), well DuckDB files folders parquet files (created via spod_convert()) closed properly prevent conflicting connections. Essentially just wrapper around DBI::dbDisconnect() reaches .$src$con object tbl_duckdb_connection connection object returned user via spod_get() spod_connect(). disonnecting database, also frees memory running gc().","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_disconnect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Safely disconnect from data and free memory — spod_disconnect","text":"","code":"spod_disconnect(tbl_con, free_mem = TRUE)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_disconnect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Safely disconnect from data and free memory — spod_disconnect","text":"tbl_con tbl_duckdb_connection connection object get either spod_get() spod_connect(). free_mem logical. Whether free memory running gc(). Defaults TRUE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_disconnect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Safely disconnect from data and free memory — spod_disconnect","text":"","code":"if (FALSE) { # \\dontrun{ od_distr <- spod_get(\"od\", zones = \"distr\", dates <- c(\"2020-01-01\", \"2020-01-02\")) spod_disconnect(od_distr) } # }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_download_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download the data files of specified type, zones, and dates — spod_download_data","title":"Download the data files of specified type, zones, and dates — spod_download_data","text":"function downloads data files specified type, zones, dates data version.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_download_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download the data files of specified type, zones, and dates — spod_download_data","text":"","code":"spod_download_data(   type = c(\"od\", \"origin-destination\", \"os\", \"overnight_stays\", \"nt\", \"number_of_trips\"),   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\", \"lau\", \"large_urban_areas\", \"gau\", \"grandes_areas_urbanas\"),   dates = NULL,   max_download_size_gb = 1,   data_dir = spod_get_data_dir(),   quiet = FALSE,   return_output = TRUE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_download_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download the data files of specified type, zones, and dates — spod_download_data","text":"type type data download. Can \"origin-destination\" (ust \"od\"), \"number_of_trips\" (just \"nt\") v1 data. v2 data \"overnight_stays\" (just \"os\") also available. data types supported future. See respective codebooks information. ADD CODEBOOKS! package zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020. max_download_size_gb maximum download size gigabytes. Defaults 1. data_dir directory data stored. Defaults value returned spod_get_data_dir() returns value environment variable SPANISH_OD_DATA_DIR temporary directory variable set. quiet logical value indicating whether suppress messages. Default FALSE. return_output Logical. TRUE, function returns character vector paths downloaded files. FALSE, function returns NULL.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_download_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download the data files of specified type, zones, and dates — spod_download_data","text":"character vector paths downloaded files. Unless return_output = FALSE, case function returns NULL.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_download_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download the data files of specified type, zones, and dates — spod_download_data","text":"","code":"if (FALSE) { # \\dontrun{ # Download the origin-destination on district level for the a date range in March 2020 spod_download_data(   type = \"od\", zones = \"districts\",   dates = c(start = \"2020-03-20\", end = \"2020-03-24\") )  # Download the origin-destination on district level for select dates in 2020 and 2021 spod_download_data(   type = \"od\", zones = \"dist\",   dates = c(\"2020-03-20\", \"2020-03-24\", \"2021-03-20\", \"2021-03-24\") )  # Download the origin-destination on municipality level using regex for a date range in March 2020 # (the regex will capture the dates 2020-03-20 to 2020-03-24) spod_download_data(   type = \"od\", zones = \"municip\",   dates = \"2020032[0-4]\" ) } # }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_filter_by_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter a duckdb conenction by dates — spod_duckdb_filter_by_dates","title":"Filter a duckdb conenction by dates — spod_duckdb_filter_by_dates","text":"IMPORTANT: function assumes table view filtered separate year, month day columns integer values. done filtering faster CSV files stored folder structure hive-style /year=2020/month=2/day=14/.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_filter_by_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter a duckdb conenction by dates — spod_duckdb_filter_by_dates","text":"","code":"spod_duckdb_filter_by_dates(con, source_view_name, new_view_name, dates)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_filter_by_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter a duckdb conenction by dates — spod_duckdb_filter_by_dates","text":"con duckdb connection source_view_name name source duckdb \"view\" (virtual table, context current package likely connected folder CSV files) new_view_name name new duckdb \"view\" (virtual table, context current package likely connected folder CSV files). dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_limit_resources.html","id":null,"dir":"Reference","previous_headings":"","what":"Set maximum memory and number of threads for a DuckDB connection — spod_duckdb_limit_resources","title":"Set maximum memory and number of threads for a DuckDB connection — spod_duckdb_limit_resources","text":"Set maximum memory number threads DuckDB connection","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_limit_resources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set maximum memory and number of threads for a DuckDB connection — spod_duckdb_limit_resources","text":"","code":"spod_duckdb_limit_resources(   con,   max_mem_gb = max(4, spod_available_ram() - 4),   max_n_cpu = parallelly::availableCores() - 1 )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_limit_resources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set maximum memory and number of threads for a DuckDB connection — spod_duckdb_limit_resources","text":"con duckdb connection max_mem_gb maximum memory use GB. conservative default 3 GB, enough resaving data DuckDB form folder CSV.gz files small enough fit memory even old computers. data analysis using already converted data (DuckDB Parquet format) raw CSV.gz data, recommended increase according available resources. max_n_cpu maximum number threads use. Defaults number available cores minus 1.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_number_of_trips.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a duckdb number of trips table — spod_duckdb_number_of_trips","title":"Create a duckdb number of trips table — spod_duckdb_number_of_trips","text":"function creates duckdb connection number trips data stored folder CSV.gz files.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_number_of_trips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a duckdb number of trips table — spod_duckdb_number_of_trips","text":"","code":"spod_duckdb_number_of_trips(   con = DBI::dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE),   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\", \"lau\", \"large_urban_areas\", \"gau\", \"grandes_areas_urbanas\"),   ver = NULL,   data_dir = spod_get_data_dir() )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_number_of_trips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a duckdb number of trips table — spod_duckdb_number_of_trips","text":"con duckdb connection object. specified, new -memory connection created. zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards. data_dir directory data stored. Defaults value returned spod_get_data_dir().","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_number_of_trips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a duckdb number of trips table — spod_duckdb_number_of_trips","text":"duckdb connection 2 views.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_od.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a duckdb connection to origin-destination data — spod_duckdb_od","title":"Creates a duckdb connection to origin-destination data — spod_duckdb_od","text":"function creates duckdb connection origin-destination data stored CSV.gz files.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_od.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a duckdb connection to origin-destination data — spod_duckdb_od","text":"","code":"spod_duckdb_od(   con = DBI::dbConnect(duckdb::duckdb(), dbdir = \":memory:\", read_only = FALSE),   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\", \"lau\", \"large_urban_areas\", \"gau\", \"grandes_areas_urbanas\"),   ver = NULL,   data_dir = spod_get_data_dir() )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_od.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a duckdb connection to origin-destination data — spod_duckdb_od","text":"con duckdb connection object. specified, new -memory connection created. zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards. data_dir directory data stored. Defaults value returned spod_get_data_dir().","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_od.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a duckdb connection to origin-destination data — spod_duckdb_od","text":"duckdb connection object 2 views: od_csv_raw - raw table view cached CSV files origin-destination data previously cached $SPANISH_OD_DATA_DIR od_csv_clean - cleaned-table view od_csv_raw column names values translated mapped English. still includes cached data. structure cleaned-views od_csv_clean follows: date Date. full date trip, including year, month, day. id_origin factor. identifier origin location trip, formatted code (e.g., '01001_AM'). id_destination factor. identifier destination location trip, formatted code (e.g., '01001_AM'). activity_origin factor. type activity origin location (e.g., 'home', 'work'). Note: available district level data. activity_destination factor. type activity destination location (e.g., 'home', ''). Note: available district level data. residence_province_ine_code factor. province residence group individual making trip, encoded according INE classification. Note: available district level data. residence_province_name factor. province residence group individuals making trip (e.g., 'Cuenca', 'Girona'). Note: available district level data. time_slot integer. time slot (hour day) trip started, represented integer (e.g., 0, 1, 2). distance factor. distance category trip, represented code (e.g., '002-005' 2-5 km). n_trips double. number trips taken within specified time slot distance. trips_total_length_km double. total length trips kilometers specified time slot distance. year double. year trip. month double. month trip. day double. day trip. structure original data od_csv_raw follows: fecha Date. date trip, including year, month, day. origen character. identifier origin location trip, formatted character string (e.g., '01001_AM'). destino character. identifier destination location trip, formatted character string (e.g., '01001_AM'). actividad_origen character. type activity origin location (e.g., 'casa', 'trabajo'). actividad_destino character. type activity destination location (e.g., 'otros', 'trabajo'). residencia character. code representing residence individual making trip (e.g., '01') according official INE classification. edad character. age individual making trip. data actaully filled 'NA' values, column removed cleaned-translated view described . periodo integer. time period trip started, represented integer (e.g., 0, 1, 2). distancia character. distance category trip, represented character string (e.g., '002-005' 2-5 km). viajes double. number trips taken within specified time period distance. viajes_km double. total length trips kilometers specified time period distance. day double. day trip. month double. month trip. year double. year trip.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_set_temp.html","id":null,"dir":"Reference","previous_headings":"","what":"Set temp file for DuckDB connection — spod_duckdb_set_temp","title":"Set temp file for DuckDB connection — spod_duckdb_set_temp","text":"Set temp file DuckDB connection","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_set_temp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set temp file for DuckDB connection — spod_duckdb_set_temp","text":"","code":"spod_duckdb_set_temp(con, temp_path = spod_get_temp_dir())"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_set_temp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set temp file for DuckDB connection — spod_duckdb_set_temp","text":"con duckdb connection temp_path path temp folder DuckDB intermediate spilling case set memory limit /physical memory computer low perform query. default set temp directory data folder defined SPANISH_OD_DATA_DIR environment variable. Otherwise, queries folders CSV files parquet files, temporary path set current R working directory, probably undesirable, current working directory can slow storage, storage may limited space, compared data folder.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_duckdb_set_temp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set temp file for DuckDB connection — spod_duckdb_set_temp","text":"duckdb connection.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_expand_dates_from_regex.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to expand dates from a regex — spod_expand_dates_from_regex","title":"Function to expand dates from a regex — spod_expand_dates_from_regex","text":"function generates sequence dates regular expression pattern. based provided regular expression.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_expand_dates_from_regex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to expand dates from a regex — spod_expand_dates_from_regex","text":"","code":"spod_expand_dates_from_regex(date_regex)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_expand_dates_from_regex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to expand dates from a regex — spod_expand_dates_from_regex","text":"date_regex regular expression match dates format yyyymmdd.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_expand_dates_from_regex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to expand dates from a regex — spod_expand_dates_from_regex","text":"character vector dates matching regex.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_files_sizes.html","id":null,"dir":"Reference","previous_headings":"","what":"Get files sizes for remote files of v1 and v2 data and save them into a csv.gz file in the inst/extdata folder. — spod_files_sizes","title":"Get files sizes for remote files of v1 and v2 data and save them into a csv.gz file in the inst/extdata folder. — spod_files_sizes","text":"Get files sizes remote files v1 v2 data save csv.gz file inst/extdata folder.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_files_sizes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get files sizes for remote files of v1 and v2 data and save them into a csv.gz file in the inst/extdata folder. — spod_files_sizes","text":"","code":"spod_files_sizes(ver = 2)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_files_sizes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get files sizes for remote files of v1 and v2 data and save them into a csv.gz file in the inst/extdata folder. — spod_files_sizes","text":"ver version data (1 2). Can . Defaults 2, v1 data updated since 2021.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get tabular data — spod_get","title":"Get tabular data — spod_get","text":"function creates DuckDB lazy table connection object specified type zones. checks missing data downloads necessary. connnection made raw CSV files gzip archives, analysing data connection may slow select days. can manipulate object using {dplyr} functions select, filter, mutate, group_by, summarise, etc. end sequence commands need add collect execute whole chain data manipulations load results memory R data.frame/tibble. See codebooks v1 v2 data vignettes spod_codebook(1) spod_codebook(2) (spod_codebook). want analyse longer periods time (especiially several months even whole data several years), consider using spod_convert spod_connect.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get tabular data — spod_get","text":"","code":"spod_get(   type = c(\"od\", \"origin-destination\", \"os\", \"overnight_stays\", \"nt\", \"number_of_trips\"),   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\"),   dates = NULL,   data_dir = spod_get_data_dir(),   quiet = FALSE,   max_mem_gb = max(4, spod_available_ram() - 4),   max_n_cpu = parallelly::availableCores() - 1,   max_download_size_gb = 1,   duckdb_target = \":memory:\",   temp_path = spod_get_temp_dir() )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get tabular data — spod_get","text":"type type data download. Can \"origin-destination\" (ust \"od\"), \"number_of_trips\" (just \"nt\") v1 data. v2 data \"overnight_stays\" (just \"os\") also available. data types supported future. See respective codebooks information. ADD CODEBOOKS! package zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020. data_dir directory data stored. Defaults value returned spod_get_data_dir() returns value environment variable SPANISH_OD_DATA_DIR temporary directory variable set. quiet logical value indicating whether suppress messages. Default FALSE. max_mem_gb maximum memory use GB. conservative default 3 GB, enough resaving data DuckDB form folder CSV.gz files small enough fit memory even old computers. data analysis using already converted data (DuckDB Parquet format) raw CSV.gz data, recommended increase according available resources. max_n_cpu maximum number threads use. Defaults number available cores minus 1. max_download_size_gb maximum download size gigabytes. Defaults 1. duckdb_target (Optional) path duckdb file save data , convertation CSV reuqested spod_convert function. specified, set \":memory:\" data stored memory. temp_path path temp folder DuckDB intermediate spilling case set memory limit /physical memory computer low perform query. default set temp directory data folder defined SPANISH_OD_DATA_DIR environment variable. Otherwise, queries folders CSV files parquet files, temporary path set current R working directory, probably undesirable, current working directory can slow storage, storage may limited space, compared data folder.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get tabular data — spod_get","text":"DuckDB lazy table connection object class tbl_duckdb_connection.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get tabular data — spod_get","text":"","code":"if (FALSE) { # \\dontrun{  # create a connection to the v1 data Sys.setenv(SPANISH_OD_DATA_DIR = \"~/path/to/your/cache/dir\") dates <- c(\"2020-02-14\", \"2020-03-14\", \"2021-02-14\", \"2021-02-14\", \"2021-02-15\") od_dist <- spod_get_od(zones = \"distr\", dates = dates)  # od dist is a table view filtered to the specified dates  # access the source connection with all dates # list tables DBI::dbListTables(od_dist$src$con) } # }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_data_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the data directory — spod_get_data_dir","title":"Get the data directory — spod_get_data_dir","text":"function retrieves data directory environment variable SPANISH_OD_DATA_DIR. environment variable set, returns temporary directory.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_data_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the data directory — spod_get_data_dir","text":"","code":"spod_get_data_dir(quiet = FALSE)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_data_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the data directory — spod_get_data_dir","text":"quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_data_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the data directory — spod_get_data_dir","text":"data directory.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_file_size_from_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Get file size from URL — spod_get_file_size_from_url","title":"Get file size from URL — spod_get_file_size_from_url","text":"Get file size URL","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_file_size_from_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get file size from URL — spod_get_file_size_from_url","text":"","code":"spod_get_file_size_from_url(x_url)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_file_size_from_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get file size from URL — spod_get_file_size_from_url","text":"x_url URL","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_file_size_from_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get file size from URL — spod_get_file_size_from_url","text":"File size MB","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v1_file_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","title":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","text":"Get latest file list XML MITMA open mobiltiy data v1 (2020-2021)","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v1_file_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","text":"","code":"spod_get_latest_v1_file_list(   data_dir = spod_get_data_dir(),   xml_url = \"https://opendata-movilidad.mitma.es/RSS.xml\" )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v1_file_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","text":"data_dir directory data stored. Defaults value returned spod_get_data_dir(). xml_url URL XML file download. Defaults \"https://opendata-movilidad.mitma.es/RSS.xml\".","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v1_file_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","text":"path downloaded XML file.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v1_file_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get latest file list from the XML for MITMA open mobiltiy data v1 (2020-2021) — spod_get_latest_v1_file_list","text":"","code":"if (FALSE) {   spod_get_latest_v1_file_list() }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v2_file_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","title":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","text":"Get latest file list XML MITMA open mobiltiy data v2 (2022 onwards)","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v2_file_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","text":"","code":"spod_get_latest_v2_file_list(   data_dir = spod_get_data_dir(),   xml_url = \"https://movilidad-opendata.mitma.es/RSS.xml\" )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v2_file_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","text":"data_dir directory data stored. Defaults value returned spod_get_data_dir(). xml_url URL XML file download. Defaults \"https://movilidad-opendata.mitma.es/RSS.xml\".","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v2_file_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","text":"path downloaded XML file.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_latest_v2_file_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get latest file list from the XML for MITMA open mobiltiy data v2 (2022 onwards) — spod_get_latest_v2_file_list","text":"","code":"if (FALSE) {   spod_get_latest_v2_file_list() }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_od.html","id":null,"dir":"Reference","previous_headings":"","what":"Load the origin-destination data for specified dates — spod_get_od","title":"Load the origin-destination data for specified dates — spod_get_od","text":"function retrieves v1 (2020-2021) v2 (2022 onwards) origin-destination data specified dates. checks requested data already cached locally downloads missing files. requested data cached, creates DuckDB connection cache data folder provides table","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_od.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load the origin-destination data for specified dates — spod_get_od","text":"","code":"spod_get_od(   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\"),   dates = NULL,   data_dir = spod_get_data_dir(),   quiet = FALSE,   max_mem_gb = max(4, spod_available_ram() - 4),   max_n_cpu = parallelly::availableCores() - 1 )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_od.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load the origin-destination data for specified dates — spod_get_od","text":"zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). dates character Date vector dates process. Kindly keep mind v1 v2 data follow different data collection methodologies may directly comparable. Therefore, try request data versions date range. need compare data versions, please refer respective codebooks methodology documents. v1 data covers period 2020-02-14 2021-05-09, v2 data covers period 2022-01-01 present notice. true dates range checked available data version every function run. possible values can following: spod_get() function, dates can set \"cached_v1\" \"cached_v2\" request data cached v1 (2020-2021) v2 (2022 onwards). case, function identify use data files downloaded cached locally, e.g. using separate previous call spod_download_data(). single date ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. vector dates ISO (YYYY-MM-DD) YYYYMMDD format. character Date object. Can non-consecutive sequence dates. date range eigher character Date object length 2 clearly named elements start end ISO (YYYY-MM-DD) YYYYMMDD format. E.g. c(start = \"2020-02-15\", end = \"2020-02-17\"); character object form YYYY-MM-DD_YYYY-MM-DD YYYYMMDD_YYYYMMDD. example, 2020-02-15_2020-02-17 20200215_20200217. regular expression match dates format YYYYMMDD. character object. example, ^202002 match dates February 2020. data_dir directory data stored. Defaults value returned spod_get_data_dir() returns value environment variable SPANISH_OD_DATA_DIR temporary directory variable set. quiet logical value indicating whether suppress messages. Default FALSE. max_mem_gb maximum memory use GB. conservative default 3 GB, enough resaving data DuckDB form folder CSV.gz files small enough fit memory even old computers. data analysis using already converted data (DuckDB Parquet format) raw CSV.gz data, recommended increase according available resources. max_n_cpu maximum number threads use. Defaults number available cores minus 1.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_od.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load the origin-destination data for specified dates — spod_get_od","text":"DuckDB table connection object. can manupulated using dplyr verbs, can loaded memory using dplyr::collect(). structure object follows: date Date. full date trip, including year, month, day. id_origin factor. identifier origin location trip, formatted code (e.g., '01001_AM'). id_destination factor. identifier destination location trip, formatted code (e.g., '01001_AM'). activity_origin factor. type activity origin location (e.g., 'home', 'work'). activity_destination factor. type activity destination location (e.g., 'home', ''). residence_province factor. province residence individual making trip (e.g. 'Cuenca', 'Girona'). time_slot integer. time slot trip started, represented integer (e.g., 0, 1, 2). distance factor. distance category trip, represented code (e.g., '002-005' 2-5 km). n_trips double. number trips taken within specified time slot distance. trips_total_length_km double. total length trips kilometers specified time slot distance. year double. year trip. month double. month trip. day double. day trip. object also contains reference source DuckDB conneciton full view cached data. can accessed using od_table$src$con. See examples . connection includes two views: od_csv_raw - raw table view cached CSV files origin-destination data previously cached $SPANISH_OD_DATA_DIR od_csv_clean - cleaned-table view od_csv_raw column names values translated mapped English. still includes cached data. View od_csv_clean structure filtered view 'od_filtered', returned spod_get_od() DuckDB table connection object. view od_csv_raw original Spanish column names values following structure: fecha Date. date trip, including year, month, day. origen character. identifier origin location trip, formatted character string (e.g., '01001_AM'). destino character. identifier destination location trip, formatted character string (e.g., '01001_AM'). actividad_origen character. type activity origin location (e.g., 'casa', 'trabajo'). actividad_destino character. type activity destination location (e.g., 'otros', 'trabajo'). residencia character. code representing residence individual making trip (e.g., '01') according official INE classification. edad character. age individual making trip. data actaully filled 'NA' values, column removed cleaned-translated view described . periodo integer. time period trip started, represented integer (e.g., 0, 1, 2). distancia character. distance category trip, represented character string (e.g., '002-005' 2-5 km). viajes double. number trips taken within specified time period distance. viajes_km double. total length trips kilometers specified time period distance. day double. day trip. month double. month trip. year double. year trip.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_od.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load the origin-destination data for specified dates — spod_get_od","text":"","code":"if (FALSE) { # \\dontrun{  # create a connection to the v1 data Sys.setenv(SPANISH_OD_DATA_DIR = \"~/path/to/your/cache/dir\") dates <- c(\"2020-02-14\", \"2020-03-14\", \"2021-02-14\", \"2021-02-14\", \"2021-02-15\") od_dist <- spod_get_od(zones = \"distr\", dates = dates)  # od dist is a table view filtered to the specified dates  # access the source connection with all dates # list tables DBI::dbListTables(od_dist$src$con) } # }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_temp_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get temporary directory for DuckDB intermediate spilling — spod_get_temp_dir","title":"Get temporary directory for DuckDB intermediate spilling — spod_get_temp_dir","text":"Get path temp folder DuckDB intermediate spilling case set memory limit /physical memory computer low perform query.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_temp_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get temporary directory for DuckDB intermediate spilling — spod_get_temp_dir","text":"","code":"spod_get_temp_dir(data_dir = spod_get_data_dir())"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_temp_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get temporary directory for DuckDB intermediate spilling — spod_get_temp_dir","text":"data_dir directory data stored. Defaults value returned spod_get_data_dir().","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_temp_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get temporary directory for DuckDB intermediate spilling — spod_get_temp_dir","text":"path temp folder DuckDB intermediate spilling.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_valid_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Get valid dates for the specified data version — spod_get_valid_dates","title":"Get valid dates for the specified data version — spod_get_valid_dates","text":"Get valid dates specified data version","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_valid_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get valid dates for the specified data version — spod_get_valid_dates","text":"","code":"spod_get_valid_dates(ver = NULL)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_valid_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get valid dates for the specified data version — spod_get_valid_dates","text":"ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_valid_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get valid dates for the specified data version — spod_get_valid_dates","text":"vector type Date possible valid dates specified data version (v1 2020-2021 v2 2020 onwards).","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones.html","id":null,"dir":"Reference","previous_headings":"","what":"Get zones — spod_get_zones","title":"Get zones — spod_get_zones","text":"Get spatial zones specified data version. Supports v1 (2020-2021) v2 (2022 onwards) data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get zones — spod_get_zones","text":"","code":"spod_get_zones(   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\", \"lau\", \"large_urban_areas\", \"gau\", \"grandes_areas_urbanas\"),   ver = NULL,   data_dir = spod_get_data_dir(),   quiet = FALSE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get zones — spod_get_zones","text":"zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\") data versions. Additionaly, can \"large_urban_areas\" (\"lau\", original Spanish \"grandes_areas_urbanas\", \"gau\") v2 data (2022 onwards). ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards. data_dir directory data stored. Defaults value returned spod_get_data_dir() returns value environment variable SPANISH_OD_DATA_DIR temporary directory variable set. quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get zones — spod_get_zones","text":"sf object (Simple Feature collection). columns include (v1 (2020-2021) v2 (2022 onwards) data: id character vector containing unique identifier zone, matched identifiers tabular data. geometry MULTIPOLYGON column containing spatial geometry zone, stored sf object. geometry projected ETRS89 / UTM zone 30N coordinate reference system (CRS), XY dimensions. Additionally, v2 (2022 onwards) data: name character vector name zone. population numeric vector representing population zone (2022).","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v1.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieves the zones for v1 data — spod_get_zones_v1","title":"Retrieves the zones for v1 data — spod_get_zones_v1","text":"function retrieves zones data specified data directory. can retrieve either \"distritos\" \"municipios\" zones data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieves the zones for v1 data — spod_get_zones_v1","text":"","code":"spod_get_zones_v1(   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\"),   data_dir = spod_get_data_dir(),   quiet = FALSE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieves the zones for v1 data — spod_get_zones_v1","text":"zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\"). data_dir directory data stored. quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieves the zones for v1 data — spod_get_zones_v1","text":"sf object (Simple Feature collection) 2 fields: id character vector containing unique identifier zone, matched identifiers tabular data. geometry MULTIPOLYGON column containing spatial geometry zone, stored sf object. geometry projected ETRS89 / UTM zone 30N coordinate reference system (CRS), XY dimensions.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieves the zones for v1 data — spod_get_zones_v1","text":"","code":"if (FALSE) {   zones <- spod_get_zones_v1() }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieves the zones data — spod_get_zones_v2","title":"Retrieves the zones data — spod_get_zones_v2","text":"function retrieves zones data specified data directory. can retrieve either \"distritos\" \"municipios\" zones data.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieves the zones data — spod_get_zones_v2","text":"","code":"spod_get_zones_v2(   zones = c(\"districts\", \"dist\", \"distr\", \"distritos\", \"municipalities\", \"muni\",     \"municip\", \"municipios\", \"lau\", \"large_urban_areas\", \"gau\", \"grandes_areas_urbanas\"),   data_dir = spod_get_data_dir(),   quiet = FALSE )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieves the zones data — spod_get_zones_v2","text":"zones zones download data. Can \"districts\" (\"dist\", \"distr\", original Spanish \"distritos\") \"municipalities\" (\"muni\", \"municip\", original Spanish \"municipios\"). data_dir directory data stored. quiet logical value indicating whether suppress messages. Default FALSE.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieves the zones data — spod_get_zones_v2","text":"sf object (Simple Feature collection) 4 fields: id character vector containing unique identifier zone, matched identifiers tabular data. name character vector name zone. population numeric vector representing population zone (2022). geometry MULTIPOLYGON column containing spatial geometry zone, stored sf object. geometry projected ETRS89 / UTM zone 30N coordinate reference system (CRS), XY dimensions.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_get_zones_v2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieves the zones data — spod_get_zones_v2","text":"","code":"if (FALSE) {   zones <- spod_get_zones_v2() }"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_is_data_version_overlaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if specified dates span both data versions — spod_is_data_version_overlaps","title":"Check if specified dates span both data versions — spod_is_data_version_overlaps","text":"function checks specified dates date ranges span v1 v2 data versions.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_is_data_version_overlaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if specified dates span both data versions — spod_is_data_version_overlaps","text":"","code":"spod_is_data_version_overlaps(dates)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_is_data_version_overlaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if specified dates span both data versions — spod_is_data_version_overlaps","text":"dates Dates vector dates check.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_is_data_version_overlaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if specified dates span both data versions — spod_is_data_version_overlaps","text":"TRUE dates span data versions, FALSE otherwise.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Match data types for normalisation — spod_match_data_type","title":"Match data types for normalisation — spod_match_data_type","text":"Match data types normalisation","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match data types for normalisation — spod_match_data_type","text":"","code":"spod_match_data_type(   type = c(\"od\", \"origin-destination\", \"viajes\", \"os\", \"overnight_stays\",     \"pernoctaciones\", \"nt\", \"number_of_trips\", \"personas\") )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match data types for normalisation — spod_match_data_type","text":"type type data match. Can \"od\", \"origin-destination\", \"os\", \"overnight_stays\", \"nt\", \"number_of_trips\".","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type_for_local_folders.html","id":null,"dir":"Reference","previous_headings":"","what":"Match data types to folders — spod_match_data_type_for_local_folders","title":"Match data types to folders — spod_match_data_type_for_local_folders","text":"Match data types folders","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type_for_local_folders.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match data types to folders — spod_match_data_type_for_local_folders","text":"","code":"spod_match_data_type_for_local_folders(   type = c(\"od\", \"origin-destination\", \"os\", \"overnight_stays\", \"nt\", \"number_of_trips\"),   ver = c(1, 2) )"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_match_data_type_for_local_folders.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match data types to folders — spod_match_data_type_for_local_folders","text":"ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_read_sql.html","id":null,"dir":"Reference","previous_headings":"","what":"Load an SQL query, glue it, dplyr::sql it — spod_read_sql","title":"Load an SQL query, glue it, dplyr::sql it — spod_read_sql","text":"Load SQL query specified file package installation directory, glue::collapse , glue::glue case variables need replaced, dplyr::sql additional safety.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_read_sql.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load an SQL query, glue it, dplyr::sql it — spod_read_sql","text":"","code":"spod_read_sql(sql_file_name)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_read_sql.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load an SQL query, glue it, dplyr::sql it — spod_read_sql","text":"sql_file_name name SQL file load package installation directory.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_read_sql.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load an SQL query, glue it, dplyr::sql it — spod_read_sql","text":"Text SQL query class sql/character.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_sql_where_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a WHERE part of an SQL query from a sequence of dates — spod_sql_where_dates","title":"Generate a WHERE part of an SQL query from a sequence of dates — spod_sql_where_dates","text":"Generate part SQL query sequence dates","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_sql_where_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a WHERE part of an SQL query from a sequence of dates — spod_sql_where_dates","text":"","code":"spod_sql_where_dates(dates)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_sql_where_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a WHERE part of an SQL query from a sequence of dates — spod_sql_where_dates","text":"dates Dates vector dates process.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_sql_where_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a WHERE part of an SQL query from a sequence of dates — spod_sql_where_dates","text":"character vector SQL query.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_clean_data_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Get clean data subfolder name — spod_subfolder_clean_data_cache","title":"Get clean data subfolder name — spod_subfolder_clean_data_cache","text":"Change subfolder name code function clean data cache apply globally, functions package use function get clean data cache path.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_clean_data_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get clean data subfolder name — spod_subfolder_clean_data_cache","text":"","code":"spod_subfolder_clean_data_cache(ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_clean_data_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get clean data subfolder name — spod_subfolder_clean_data_cache","text":"ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_clean_data_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get clean data subfolder name — spod_subfolder_clean_data_cache","text":"Character string subfolder name clean data cache.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_raw_data_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Get raw data cache subfolder name — spod_subfolder_raw_data_cache","title":"Get raw data cache subfolder name — spod_subfolder_raw_data_cache","text":"Change subfolder name code function raw data cache apply globally, functions package use function get raw data cache path.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_raw_data_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get raw data cache subfolder name — spod_subfolder_raw_data_cache","text":"","code":"spod_subfolder_raw_data_cache(ver = 1)"},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_raw_data_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get raw data cache subfolder name — spod_subfolder_raw_data_cache","text":"ver Integer. Can 1 2. version data use. v1 spans 2020-2021, v2 covers 2022 onwards.","code":""},{"path":"https://robinlovelace.github.io/spanishoddata/reference/spod_subfolder_raw_data_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get raw data cache subfolder name — spod_subfolder_raw_data_cache","text":"Character string subfolder name raw data cache.","code":""}]
